{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.vocab = set()\n",
    "        self.reviews = []\n",
    "        self.classification = []\n",
    "\n",
    "    def read_data(self, path: str) -> list:\n",
    "        # Find all the .txt files at the path, remove the README from the list\n",
    "        file_paths = glob.glob(path + \"/*.txt\")\n",
    "        file_paths.remove(path + \"/README.txt\")\n",
    "\n",
    "        corpora = []\n",
    "        # Read each file in the list of files\n",
    "        for file_path in file_paths:\n",
    "            f = open(file_path, \"r\")\n",
    "            # Add the data to an array of corpora\n",
    "            corpora.append(f.read())\n",
    "\n",
    "        return corpora\n",
    "\n",
    "    def preprocess(self, corpora: list):\n",
    "        self.reviews = []\n",
    "        self.classification = []\n",
    "        # process the raw data of each corpus in the list\n",
    "        for corpus in corpora:\n",
    "            self.process_raw(corpus)\n",
    "\n",
    "    def process_raw(self, raw: str):\n",
    "        # split over the lines (## defines a line and is on each new line as defined by README)\n",
    "        lines = raw.replace(\"[t]\", \"\").splitlines()\n",
    "        # remove '[t]' tags\n",
    "        # lines = [ele for ele in lines if ele != \"[t]\"]\n",
    "\n",
    "        # process each line in the text, add the result to an array\n",
    "        for line in lines:\n",
    "            if len(line) != 0:\n",
    "                processed_review, review_type = self.process_line(line)\n",
    "                if len(review_type) != 0:\n",
    "                    num_pos = 3 * review_type.count(\"+3\") + 2 * review_type.count(\"+2\") + review_type.count(\"+1\")\n",
    "                    num_neg = 3 * review_type.count(\"-3\") + 2 * review_type.count(\"-2\") + review_type.count(\"-1\")\n",
    "                    # print(review_type, end=\" \")\n",
    "                    # print(f\"pos: {num_pos} neg: {num_neg}\")\n",
    "                    if num_pos > num_neg:\n",
    "                        self.classification.append(1)\n",
    "                    else:\n",
    "                        self.classification.append(0)\n",
    "                    self.reviews.append(processed_review)\n",
    "\n",
    "    def process_line(self, line: str) -> tuple[list, str]:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        # Add stopwords not in nltk list, these would appear in top 50 list otherwise\n",
    "        stop_words.update([\"ive\", \"im\"])\n",
    "\n",
    "        # Get the substring before the ## delimiter\n",
    "        try:\n",
    "            review_type = line[:line.index(\"##\")]\n",
    "        except:\n",
    "            print(line)\n",
    "            review_type = \"\"\n",
    "\n",
    "        # Remove any information before '##'\n",
    "        line = re.sub(r'^.*?##', '', line)\n",
    "        # Convert to lower case\n",
    "        line_lwr = line.lower()\n",
    "        # Remove everything except alpha characters, numbers, and whitespace\n",
    "        line_clean = re.sub(r'[^a-z0-9\\s]+', '', line_lwr)\n",
    "        # Tokenize the line\n",
    "        line_tokens = word_tokenize(line_clean)\n",
    "        # Remove stopwords\n",
    "        filtered_line = [w for w in line_tokens if w not in stop_words]\n",
    "\n",
    "        return filtered_line, review_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "variety of colours[+2] - Colors: 10 variety of HOT colors made it difficult to choose from. \n",
      "touch pad[-2], design[-1], volume control[-1] Weak Points: - Touch Pad: design could be better - Volume Control: controlled through the vertical strip, but purchasing a headphone with built-in volume control will do the trick. \n",
      "\n",
      "\n",
      "\n",
      "touchpad[-1][u] The touch buttons do take a little getting used to and I don't like how the scroll button is the same button used as an \"enter\" key, but you get used to it and it isn't a big deal. \n",
      "\n",
      "built[+3][u] I've dropped the device several times onto hard surfaces, and it still works flawlessly.     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You may need to briefly disable various spam blockers, cookie swatters, and antivirus programs (I know, I know -- get offline first). \n",
      "\n",
      "\n",
      "#3It's been dropped, shuffled, kicked, and Lumbered. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "player[+1][u] As I said, I don't regret the purchase at all.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I've heard many good reviews of this product and I wonder if maybe I just had bad luck.  \n",
      "\t       \n",
      "\n",
      "\n",
      "transfer speed[-2] #Right now, the Creative software transfers subscription music files very slowly. \n",
      "\n",
      "\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    neural = NeuralNetwork()\n",
    "    corpora = neural.read_data(\"product_reviews\") # specify the directory path to the review files\n",
    "\n",
    "    neural.preprocess(corpora)\n",
    " \n",
    "test = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
